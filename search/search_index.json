{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"TinyExplorer DetectionApp","text":"Main application interface showing file selection, model options, and confidence threshold controls"},{"location":"#overview","title":"Overview","text":"<p>The TinyExplorer DetectionApp is a user-friendly graphical interface designed specifically for developmental psychologists working with infants and young children. This toolbox integrates state-of-the-art open-source face recognition algorithms into an easy-to-use software package, streamlining the process of analyzing facial data in developmental research.</p>"},{"location":"#features","title":"Features","text":"<ul> <li>Simple graphical user interface for easy operation</li> <li>Integration of cutting-edge face recognition models</li> <li>Batch processing capabilities for efficient analysis of large datasets</li> <li>Customizable confidence thresholds for detection accuracy</li> </ul>"},{"location":"#basic-usage","title":"Basic Usage","text":""},{"location":"#install-a-prebuilt-release-recommended","title":"Install a Prebuilt Release (recommended)","text":"<ul> <li>Download the latest installer for your OS from the Releases page.</li> <li>Run the installer and launch the app.</li> </ul>"},{"location":"#build-locally-with-npm-fallback","title":"Build Locally with npm (fallback)","text":"<p>If no release exists for your system or the installer doesn\u2019t work, you can build locally.</p> <ul> <li>Install dependencies:   <pre><code>npm install\n</code></pre></li> <li>Start in development:   <pre><code>npm run start\n</code></pre></li> <li>Create a distributable build:   <pre><code>npm run build\n</code></pre></li> </ul> <p>See also: Supported File Formats and Getting Started.</p>"},{"location":"#documentation-sections","title":"Documentation Sections","text":"<ul> <li>Getting Started</li> <li>Main Features</li> <li>Understanding Results</li> <li>Advanced Options</li> <li>Troubleshooting</li> <li>Support and Updates</li> <li>About</li> </ul>"},{"location":"#copyright-attribution","title":"Copyright &amp; Attribution","text":"<p>\u00a9 Cardiff Babylab</p>"},{"location":"#project-team","title":"Project Team","text":"<ul> <li>Concept and Project Management: Teodor Nikolov &amp; Hana D'Souza</li> <li>Lead Development and Implementation: Tamas Foldes</li> <li>Code Contributions: Ziye Zhang &amp; Teodor Nikolov</li> </ul>"},{"location":"#funding","title":"Funding","text":"<p>This work was supported by a James S. McDonnell Foundation (JSMF) Opportunity Award and a UKRI Future Leaders Fellowship (MR/X032922/1) awarded to HD.</p>"},{"location":"about/","title":"About TinyExplorer DetectionApp","text":""},{"location":"about/#about-the-project","title":"About the Project","text":"<p>TinyExplorer DetectionApp is a desktop application designed for developmental research, providing robust face detection capabilities using state-of-the-art YOLO and RetinaFace models. The app enables researchers to efficiently process large volumes of images and videos, extracting face detection data for analysis.</p>"},{"location":"about/#copyright-attribution","title":"Copyright &amp; Attribution","text":"<p>\u00a9 Cardiff Babylab</p>"},{"location":"about/#project-team","title":"Project Team","text":"<ul> <li>Concept and Project Management: Teodor Nikolov &amp; Hana D'Souza</li> <li>Lead Development and Implementation: Tamas Foldes</li> <li>Code Contributions: Ziye Zhang &amp; Teodor Nikolov</li> </ul>"},{"location":"about/#research-applications","title":"Research Applications","text":"<p>This application was developed to support developmental psychology research at Cardiff Babylab, enabling:</p> <ul> <li>Automated face detection in experimental recordings</li> <li>Batch processing of research data</li> <li>Standardized data extraction for statistical analysis</li> <li>Cross-platform deployment for research teams</li> </ul>"},{"location":"about/#technical-stack","title":"Technical Stack","text":"<p>The application combines modern web technologies with machine learning frameworks:</p> <ul> <li>Frontend: React with TypeScript</li> <li>Desktop Framework: Electron</li> <li>Backend: Python with Flask</li> <li>Machine Learning: YOLO (PyTorch) and RetinaFace (TensorFlow)</li> <li>Cross-platform: Windows, macOS, and Linux support</li> </ul>"},{"location":"about/#license","title":"License","text":"<p>This project is released under the MIT License. See the LICENSE file for details.</p>"},{"location":"about/#acknowledgments","title":"Acknowledgments","text":"<p>Special thanks to the Cardiff Babylab team and all researchers who provided feedback and testing during development.</p>"},{"location":"about/#contact","title":"Contact","text":"<p>For questions about the application or research collaborations, please contact the Cardiff Babylab team.</p>"},{"location":"about/#funding","title":"Funding","text":"<p>This work was supported by a James S. McDonnell Foundation (JSMF) Opportunity Award and a UKRI Future Leaders Fellowship (MR/X032922/1) awarded to HD.</p> <p>TinyExplorer DetectionApp - Advancing developmental research through innovative technology</p>"},{"location":"advanced-options/","title":"Advanced Options","text":""},{"location":"advanced-options/#batch-processing","title":"Batch Processing","text":"<p>Process entire folders of images and videos in one run.</p>"},{"location":"advanced-options/#steps","title":"Steps","text":"<p>Before You Start</p> <p>See Supported File Formats for compatible image and video types.</p> <ol> <li> <p>Select Input Type    In the input section, choose Folder (instead of File)</p> </li> <li> <p>Choose Your Folder    Select a folder containing supported images and/or videos</p> </li> <li> <p>Configure Detection Settings </p> </li> <li>Pick a Model from the dropdown</li> <li> <p>Set the Confidence Threshold using the slider</p> </li> <li> <p>Start Processing    Click Start Detection to begin batch processing</p> </li> </ol>"},{"location":"advanced-options/#outputs","title":"Outputs","text":"<ul> <li>A timestamped results folder is created.</li> <li>Processed images (and extracted video frames, if enabled) are saved under <code>results/</code>.</li> <li>A comprehensive <code>detection_results.csv</code> contains all detections with coordinates and scores.</li> <li>A <code>summary.csv</code> provides per-file statistics and overall counts.</li> </ul> <p>Tip: Close other intensive applications for faster batch runs, especially with large videos or high-resolution imagery.</p>"},{"location":"advanced-options/#performance-considerations","title":"Performance Considerations","text":"<ul> <li>Model Selection: YOLOv8n-face offers faster processing; YOLOv8l-face provides higher accuracy.</li> <li>Video Processing: Videos take longer than images\u2014ensure your hardware can handle large batches.</li> <li>Memory Usage: High-resolution media can consume significant memory. Close other intensive applications for best performance.</li> </ul>"},{"location":"getting-started/","title":"Getting Started","text":"<p>Welcome to the TinyExplorer DetectionApp user guide. This section helps you install the application and become familiar with the interface.</p>"},{"location":"getting-started/#installation","title":"Installation","text":"<p>Choose your operating system below for specific installation instructions:</p> macOSWindowsUbuntu/Linux"},{"location":"getting-started/#macos-installation-guide","title":"macOS Installation Guide","text":"<p>Since TinyExplorer DetectionApp is not signed with an Apple Developer certificate, macOS requires additional steps to ensure the app can run safely on your system.</p>"},{"location":"getting-started/#step-1-download-the-application","title":"Step 1: Download the Application","text":"<ol> <li>Visit the Releases page</li> <li>Download the latest <code>.dmg</code> file for macOS</li> <li>Open the downloaded <code>.dmg</code> file</li> <li>Drag TinyExplorer DetectionApp to your Applications folder</li> </ol>"},{"location":"getting-started/#step-2-remove-quarantine-required","title":"Step 2: Remove Quarantine (Required)","text":"<p>Why is this necessary?</p> <p>macOS quarantines unsigned applications downloaded from the internet for security. Since we don't have an Apple Developer certificate (which costs $99/year), you need to manually approve the app. This is safe as long as you downloaded it from our official GitHub releases.</p> <ol> <li>Open Terminal (found in Applications \u2192 Utilities)</li> <li>Type the following command but don't press Enter yet:    <pre><code>sudo xattr -r -d com.apple.quarantine \n</code></pre></li> <li>Add a space after the command</li> <li>Drag and drop the TinyExplorer app from your Applications folder into the Terminal window</li> <li>This will automatically add the correct path to your app</li> <li>The complete command should look like:      <pre><code>sudo xattr -r -d com.apple.quarantine /Applications/TinyExplorer\\ FaceDetectionApp.app\n</code></pre></li> <li>Press Enter and type your Mac password when prompted</li> </ol> <p>What does this command do?</p> <ul> <li><code>sudo</code> - Runs the command with administrator privileges</li> <li><code>xattr</code> - Modifies file attributes</li> <li><code>-r</code> - Applies recursively to all files in the app</li> <li><code>-d com.apple.quarantine</code> - Removes the quarantine flag</li> <li>The path points to your installed application</li> </ul>"},{"location":"getting-started/#step-3-launch-the-application","title":"Step 3: Launch the Application","text":"<ol> <li>Go to your Applications folder</li> <li>Double-click TinyExplorer DetectionApp</li> <li>If you see a security warning, click Open to proceed</li> <li>The app will now launch successfully!</li> </ol> <p>Installation Complete!</p> <p>The app is now installed and ready to use. You only need to do this once.</p>"},{"location":"getting-started/#windows-installation-guide","title":"Windows Installation Guide","text":"<p>Coming Soon</p> <p>Windows installer is currently in development. Please check back later or build from source using the instructions below.</p>"},{"location":"getting-started/#build-from-source-temporary-solution","title":"Build from Source (Temporary Solution)","text":"<ol> <li>Install Node.js (version 18 or higher)</li> <li>Clone the repository:    <pre><code>git clone https://github.com/cardiff-babylab/tinyexplorer-detectionapp.git\ncd tinyexplorer-detectionapp\n</code></pre></li> <li>Install dependencies:    <pre><code>npm install\n</code></pre></li> <li>Start the application:    <pre><code>npm run start\n</code></pre></li> </ol>"},{"location":"getting-started/#ubuntulinux-installation-guide","title":"Ubuntu/Linux Installation Guide","text":"<p>Coming Soon</p> <p>Linux AppImage/deb package is currently in development. Please check back later or build from source using the instructions below.</p>"},{"location":"getting-started/#build-from-source-temporary-solution_1","title":"Build from Source (Temporary Solution)","text":"<ol> <li>Install Node.js and npm:    <pre><code>sudo apt update\nsudo apt install nodejs npm\n</code></pre></li> <li>Clone the repository:    <pre><code>git clone https://github.com/cardiff-babylab/tinyexplorer-detectionapp.git\ncd tinyexplorer-detectionapp\n</code></pre></li> <li>Install dependencies:    <pre><code>npm install\n</code></pre></li> <li>Start the application:    <pre><code>npm run start\n</code></pre></li> </ol>"},{"location":"getting-started/#first-launch","title":"First Launch","text":"<p>When you first launch the application, you'll see the main interface with all the controls needed for face detection.</p>"},{"location":"getting-started/#interface-overview","title":"Interface Overview","text":"Main application interface showing file selection, model options, and confidence threshold controls <p>The main interface contains:</p> <ul> <li>File/Folder Selection \u2013 choose images or videos for processing</li> <li>Model Selection \u2013 pick the face detection model</li> <li>Confidence Threshold \u2013 adjust detection sensitivity</li> <li>Start \u2013 begin the recognition process</li> <li>Results Display \u2013 view detection outputs</li> </ul>"},{"location":"getting-started/#see-also","title":"See Also","text":"<ul> <li>Basic Usage: installation options and local build steps \u2014 see Basic Usage.</li> <li>Supported File Types: list of compatible images and videos \u2014 see Supported File Formats.</li> </ul>"},{"location":"main-features/","title":"Main Features","text":""},{"location":"main-features/#file-and-folder-selection","title":"File and Folder Selection","text":"<ul> <li>Browse and select individual image or video files</li> <li>Browse and select entire folders containing multiple images and videos</li> </ul>"},{"location":"main-features/#model-selection","title":"Model Selection","text":"<p>Choose from multiple face detection models:</p> <ul> <li>YOLOv8n-face (Nano): fastest inference, smallest size (~2.7 MB); lower accuracy; ideal for real\u2011time or limited resources.</li> <li>YOLOv8m-face (Medium): balanced speed and accuracy (~27.3 MB); solid default for most tasks.</li> <li>YOLOv8l-face (Large): highest accuracy within v8 (~59.2 MB); slower inference; best for high precision.</li> <li>YOLOv11m-face (Medium): newer generation with improved accuracy/speed trade\u2011offs; good general\u2011purpose choice on modern hardware.</li> <li>YOLOv11l-face (Large): higher accuracy variant; increased compute and memory cost.</li> <li>YOLOv12l-face (Large): latest large model; highest accuracy and resource use; recommended for offline batch processing.</li> <li>RetinaFace: alternative architecture with facial landmarks; good speed/accuracy for feature localization. Note: available on Apple Silicon (arm64) macOS only. Source: serengil/retinaface.</li> </ul> <p>The app automatically downloads required model weights when needed.</p>"},{"location":"main-features/#model-sources","title":"Model Sources","text":"<ul> <li>YOLO face weights: akanametov/yolo-face</li> <li>RetinaFace implementation: serengil/retinaface</li> </ul>"},{"location":"main-features/#confidence-threshold-adjustment","title":"Confidence Threshold Adjustment","text":"<ul> <li>Adjustable slider from 0.0 to 1.0</li> <li>Default confidence values tailored to each model</li> </ul>"},{"location":"main-features/#face-recognition-process","title":"Face Recognition Process","text":"<ul> <li>Works with images and videos</li> <li>Batch processing for multiple files in a folder</li> <li>Real-time progress bar and percentage display</li> <li>Detailed logging of the recognition process</li> </ul>"},{"location":"main-features/#results-and-output","title":"Results and Output","text":"<ul> <li>Timestamped results folder</li> <li>CSV output with detailed detection data</li> <li>Summary CSV with overall statistics</li> <li>Visual results saved for images and video frames</li> <li>Results folder opens automatically when processing completes</li> </ul>"},{"location":"main-features/#user-interface","title":"User Interface","text":"<ul> <li>Intuitive GUI with file/folder selection, model choice, and confidence adjustment</li> <li>Real-time status updates in the window</li> <li>Error handling and user notifications</li> </ul>"},{"location":"main-features/#supported-file-formats","title":"Supported File Formats","text":"<p>Images - JPEG (.jpg, .jpeg) - PNG (.png) - BMP (.bmp)</p> <p>Videos - MP4 (.mp4) - AVI (.avi) - MOV (.mov)</p> <p>You can select individual files or folders containing these formats for processing.</p>"},{"location":"support/","title":"Support and Updates","text":""},{"location":"support/#getting-help","title":"Getting Help","text":"<ul> <li>Consult this documentation for guidance</li> <li>Report bugs or request features on the GitHub issues page</li> <li>Join discussions at GitHub Discussions</li> </ul>"},{"location":"support/#checking-for-updates","title":"Checking for Updates","text":"<ol> <li>Open the application and go to Help &gt; Check for Updates.</li> <li>Follow prompts if a new version is available.</li> <li>You can also visit the GitHub releases page to download updates manually.</li> </ol> <p>Thank you for using the TinyExplorer DetectionApp!</p>"},{"location":"troubleshooting/","title":"Troubleshooting","text":""},{"location":"troubleshooting/#common-issues","title":"Common Issues","text":"<p>If you encounter problems, consult these resources:</p> <ul> <li>Report bugs on the GitHub issues page</li> <li>Ask questions on GitHub Discussions</li> </ul>"},{"location":"troubleshooting/#error-messages","title":"Error Messages","text":"<ol> <li>Review the FAQs below for quick answers.</li> <li>Search existing issues to see if the problem has been reported.</li> <li>If unresolved, open a new issue with:</li> <li>Description of the problem</li> <li>Steps to reproduce</li> <li>Exact error message</li> <li>System information (OS, browser version, etc.)</li> </ol>"},{"location":"troubleshooting/#faqs","title":"FAQs","text":"<p>Visit the Q&amp;A section on GitHub Discussions for frequently asked questions. Start a new discussion if you need further help.</p> <p>We appreciate your feedback and contributions!</p>"},{"location":"understanding-results/","title":"Understanding Results","text":""},{"location":"understanding-results/#csv-output","title":"CSV Output","text":""},{"location":"understanding-results/#resultscsv","title":"results.csv","text":""},{"location":"understanding-results/#single-file-mode-image-or-video","title":"Single File Mode (Image or Video)","text":"<ul> <li>filename \u2013 processed file or video frame name</li> <li>face_detected \u2013 1 if a face was found, 0 otherwise</li> <li>face_count \u2013 number of faces in the image or frame</li> <li>face_X_x, face_X_y \u2013 center coordinates of each face bounding box</li> <li>face_X_width, face_X_height \u2013 dimensions of each face bounding box</li> <li>face_X_confidence \u2013 confidence score for each detected face</li> </ul>"},{"location":"understanding-results/#folder-mode","title":"Folder Mode","text":"<p>Same columns as single file mode but includes entries for every processed file or video frame in the folder.</p>"},{"location":"understanding-results/#summarycsv","title":"summary.csv","text":""},{"location":"understanding-results/#single-file-mode","title":"Single File Mode","text":"<ul> <li>path \u2013 name of the processed file</li> <li>type \u2013 <code>image</code> or <code>video</code></li> <li>total_processed_frames \u2013 number of frames processed (1 for images)</li> <li>total_duration \u2013 video duration in seconds (N/A for images)</li> <li>processed_frames_with_faces \u2013 frames where faces were detected</li> <li>face_percentage \u2013 percentage of frames with faces</li> <li>model \u2013 detection model used</li> <li>confidence_threshold \u2013 threshold applied during detection</li> </ul>"},{"location":"understanding-results/#folder-mode_1","title":"Folder Mode","text":"<p>Same columns as single file mode but provides two rows summarising: 1. All images in the folder 2. All videos in the folder</p> <p>Each row contains aggregate values for path, type, total processed frames, total duration, frames with faces, face percentage, model, and confidence threshold.</p>"},{"location":"understanding-results/#image-output","title":"Image Output","text":"<p>The application saves visual outputs for all images and video frames with detected faces.</p>"},{"location":"understanding-results/#bounding-boxes","title":"Bounding Boxes","text":"<ul> <li>Green rectangles show each detected face and match the coordinates in <code>results.csv</code></li> </ul>"},{"location":"understanding-results/#confidence-scores","title":"Confidence Scores","text":"<ul> <li>Each bounding box displays the detection confidence between 0 and 1</li> <li>Values correspond to <code>face_X_confidence</code> in <code>results.csv</code></li> </ul>"},{"location":"understanding-results/#output-file-names","title":"Output File Names","text":"<ul> <li>For images, the output file retains the original name</li> <li>For videos, each processed frame is saved separately using the format <code>[video_name]_[frame_number]_[timestamp].jpg</code></li> </ul> <p>These outputs make it easy to verify detection results and assess model performance.</p>"}]}